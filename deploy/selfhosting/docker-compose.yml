name: admyral

services:
    backend:
        build: ../../backend
        env_file:
            - ./.env
        command: >
            sh -c "alembic upgrade head && python scripts/populate_db_with_workflow_templates_library.py && uvicorn app.main:app --host 0.0.0.0 --port 80"
        environment:
            DATABASE_URL_ASYNCPG: postgresql+asyncpg://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
            JWT_SECRET: ${JWT_SECRET}
            WEBHOOK_SIGNING_SECRET: ${WEBHOOK_SIGNING_SECRET}
            OPENAI_API_KEY: ${OPENAI_API_KEY}

            # Uncomment to enable quotas - the quotas can be set in the .env file
            # WORKFLOW_RUN_HOURLY_QUOTA: ${WORKFLOW_RUN_HOURLY_QUOTA}
            # WORKFLOW_RUN_TIMEOUT_IN_MINUTES: ${WORKFLOW_RUN_TIMEOUT_IN_MINUTES}
            # WORKFLOW_ASSISTANT_DAILY_QUOTA: ${WORKFLOW_ASSISTANT_DAILY_QUOTA}
        healthcheck:
            test: ["CMD", "curl", "-f", "http://0.0.0.0:80/health"]
            timeout: 5s
            interval: 5s
            retries: 3
        restart: unless-stopped
        depends_on:
            studio:
                condition: service_healthy
            auth:
                condition: service_healthy

    workflow-runner:
        container_name: workflow-runner
        image: admyralai/workflow-runner:latest
        env_file:
            - ./.env
        ports:
            - 5000:80
        environment:
            JWT_SECRET: ${JWT_SECRET}
            DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
            DATABASE_CONNECTION_POOL_SIZE: ${DATABASE_CONNECTION_POOL_SIZE}
            CREDENTIALS_SECRET: ${CREDENTIALS_SECRET}
            OPENAI_API_KEY: ${OPENAI_API_KEY}
            RESEND_API_KEY: ${RESEND_API_KEY}
            RESEND_EMAIL: ${RESEND_EMAIL}
            MS_TEAMS_OAUTH_CLIENT_ID: ${MS_TEAMS_OAUTH_CLIENT_ID}
            MS_TEAMS_OAUTH_CLIENT_SECRET: ${MS_TEAMS_OAUTH_CLIENT_SECRET}

            # Uncomment to enable quotas - the quotas can be set in the .env file
            # WORKFLOW_RUN_HOURLY_QUOTA: ${WORKFLOW_RUN_HOURLY_QUOTA}
            # WORKFLOW_RUN_TIMEOUT_IN_MINUTES: ${WORKFLOW_RUN_TIMEOUT_IN_MINUTES}
        healthcheck:
            test: ["CMD", "curl", "-f", "http://0.0.0.0:80/health"]
            timeout: 5s
            interval: 5s
            retries: 3
        restart: unless-stopped
        depends_on:
            studio:
                condition: service_healthy
            auth:
                condition: service_healthy

    web:
        build:
            context: ../../web
            args:
                NEXT_PUBLIC_SUPABASE_URL_CLIENT: ${SUPABASE_URL}
                NEXT_PUBLIC_SUPABASE_ANON_KEY: ${ANON_KEY}
                NEXT_PUBLIC_SUPPORT_EMAIL: ${SUPPORT_EMAIL}
                NEXT_PUBLIC_WORKFLOW_RUNNER_API_URL: ${ADMYRAL_WORKFLOW_RUNNER_API_URL}
                NEXT_PUBLIC_POSTHOG_KEY: ${POSTHOG_KEY}
                NEXT_PUBLIC_POSTHOG_HOST: ${POSTHOG_HOST}
                NEXT_PUBLIC_DISABLE_GOOGLE_AUTH: true
                NEXT_PUBLIC_DISABLE_MICROSOFT_AUTH: true
                NEXT_PUBLIC_DISABLE_GITHUB_AUTH: true
                NEXT_PUBLIC_DOMAIN: ${ADMYRAL_SITE_URL}
                NEXT_PUBLIC_MS_TEAMS_OAUTH_CLIENT_ID: ${MS_TEAMS_OAUTH_CLIENT_ID}
        env_file:
            - ./.env
        ports:
            - 3000:3000
        environment:
            WORKFLOW_RUNNER_API_URL: http://workflow-runner
            SUPABASE_URL_SERVER: http://kong:8000
            BACKEND_API_URL: http://backend
            CREDENTIALS_SECRET: ${CREDENTIALS_SECRET}
            WEBHOOK_SIGNING_SECRET: ${WEBHOOK_SIGNING_SECRET}
            MS_TEAMS_OAUTH_CLIENT_SECRET: ${MS_TEAMS_OAUTH_CLIENT_SECRET}
        depends_on:
            backend:
                condition: service_healthy
            workflow-runner:
                condition: service_healthy
        healthcheck:
            test:
                [
                    "CMD",
                    "wget",
                    "--no-verbose",
                    "--tries=1",
                    "--spider",
                    "http://127.0.0.1:3000/health",
                ]
            interval: 1m30s
            timeout: 30s
            retries: 5
            start_period: 30s

    #############################################################################
    # Supabase
    #############################################################################

    studio:
        container_name: supabase-studio
        image: supabase/studio:20240422-5cf8f30
        restart: unless-stopped
        healthcheck:
            test:
                [
                    "CMD",
                    "node",
                    "-e",
                    "require('http').get('http://' + process.env.HOSTNAME + ':3000/api/profile', (r) => {if (r.statuscode !== 200) throw new error(r.statuscode)})",
                ]
            timeout: 5s
            interval: 5s
            retries: 3
        depends_on:
            analytics:
                condition: service_healthy
        environment:
            STUDIO_PG_META_URL: http://meta:8080
            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}

            DEFAULT_ORGANIZATION_NAME: Admyral
            DEFAULT_PROJECT_NAME: Admyral

            SUPABASE_URL: http://kong:8000
            SUPABASE_PUBLIC_URL: ${SUPABASE_URL}
            SUPABASE_ANON_KEY: ${ANON_KEY}
            SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}

            LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
            LOGFLARE_URL: http://analytics:4000
            NEXT_PUBLIC_ENABLE_LOGS: true
            # Comment to use Big Query backend for analytics
            NEXT_ANALYTICS_BACKEND_PROVIDER: postgres
            # Uncomment to use Big Query backend for analytics
            # NEXT_ANALYTICS_BACKEND_PROVIDER: bigquery

    kong:
        container_name: supabase-kong
        image: kong:2.8.1
        restart: unless-stopped
        # https://unix.stackexchange.com/a/294837
        entrypoint: bash -c 'eval "echo \"$$(cat ~/temp.yml)\"" > ~/kong.yml && /docker-entrypoint.sh kong docker-start'
        ports:
            - 8000:8000/tcp
            - 8443:8443/tcp
            # - ${KONG_HTTP_PORT}:8000/tcp
            # - ${KONG_HTTPS_PORT}:8443/tcp
        depends_on:
            analytics:
                condition: service_healthy
        environment:
            KONG_DATABASE: "off"
            KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
            # https://github.com/supabase/cli/issues/14
            KONG_DNS_ORDER: LAST,A,CNAME
            KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
            KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
            KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
            SUPABASE_ANON_KEY: ${ANON_KEY}
            SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
            DASHBOARD_USERNAME: ${DASHBOARD_USERNAME}
            DASHBOARD_PASSWORD: ${DASHBOARD_PASSWORD}
        volumes:
            # https://github.com/supabase/supabase/issues/12661
            - ./volumes/api/kong.yml:/home/kong/temp.yml:ro

    auth:
        container_name: supabase-auth
        image: supabase/gotrue:v2.151.0
        depends_on:
            db:
                # Disable this if you are using an external Postgres database
                condition: service_healthy
            analytics:
                condition: service_healthy
        healthcheck:
            test:
                [
                    "CMD",
                    "wget",
                    "--no-verbose",
                    "--tries=1",
                    "--spider",
                    "http://localhost:9999/health",
                ]
            timeout: 5s
            interval: 5s
            retries: 3
        restart: unless-stopped
        environment:
            GOTRUE_API_HOST: 0.0.0.0
            GOTRUE_API_PORT: 9999
            API_EXTERNAL_URL: ${SUPABASE_URL}

            GOTRUE_DB_DRIVER: postgres
            GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

            GOTRUE_SITE_URL: ${ADMYRAL_SITE_URL}
            GOTRUE_URI_ALLOW_LIST: ""
            GOTRUE_DISABLE_SIGNUP: "false"

            GOTRUE_JWT_ADMIN_ROLES: service_role
            GOTRUE_JWT_AUD: authenticated
            GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
            GOTRUE_JWT_EXP: 3600
            GOTRUE_JWT_SECRET: ${JWT_SECRET}

            GOTRUE_EXTERNAL_EMAIL_ENABLED: ${ENABLE_EMAIL_SIGNUP}
            GOTRUE_EXTERNAL_ANONYMOUS_USERS_ENABLED: "false"
            GOTRUE_MAILER_AUTOCONFIRM: ${ENABLE_EMAIL_AUTOCONFIRM}
            # GOTRUE_MAILER_SECURE_EMAIL_CHANGE_ENABLED: true
            # GOTRUE_SMTP_MAX_FREQUENCY: 1s

            GOTRUE_SMTP_ADMIN_EMAIL: ${SMTP_ADMIN_EMAIL}
            GOTRUE_SMTP_HOST: ${SMTP_HOST}
            GOTRUE_SMTP_PORT: ${SMTP_PORT}
            GOTRUE_SMTP_USER: ${SMTP_USER}
            GOTRUE_SMTP_PASS: ${SMTP_PASS}
            GOTRUE_SMTP_SENDER_NAME: ${SMTP_SENDER_NAME}

            GOTRUE_MAILER_URLPATHS_INVITE: "/auth/v1/verify"
            GOTRUE_MAILER_URLPATHS_CONFIRMATION: "/auth/v1/verify"
            GOTRUE_MAILER_URLPATHS_RECOVERY: "/auth/v1/verify"
            GOTRUE_MAILER_URLPATHS_EMAIL_CHANGE: "/auth/v1/verify"

            GOTRUE_EXTERNAL_PHONE_ENABLED: "false"
            GOTRUE_SMS_AUTOCONFIRM: "false"

            # Uncomment to enable custom access token hook. You'll need to create a public.custom_access_token_hook function and grant necessary permissions.
            # See: https://supabase.com/docs/guides/auth/auth-hooks#hook-custom-access-token for details
            # GOTRUE_HOOK_CUSTOM_ACCESS_TOKEN_ENABLED="true"
            # GOTRUE_HOOK_CUSTOM_ACCESS_TOKEN_URI="pg-functions://postgres/public/custom_access_token_hook"

            # GOTRUE_HOOK_MFA_VERIFICATION_ATTEMPT_ENABLED="true"
            # GOTRUE_HOOK_MFA_VERIFICATION_ATTEMPT_URI="pg-functions://postgres/public/mfa_verification_attempt"

            # GOTRUE_HOOK_PASSWORD_VERIFICATION_ATTEMPT_ENABLED="true"
            # GOTRUE_HOOK_PASSWORD_VERIFICATION_ATTEMPT_URI="pg-functions://postgres/public/password_verification_attempt"

    rest:
        container_name: supabase-rest
        image: postgrest/postgrest:v12.0.1
        depends_on:
            db:
                # Disable this if you are using an external Postgres database
                condition: service_healthy
            analytics:
                condition: service_healthy
        restart: unless-stopped
        environment:
            PGRST_DB_URI: postgres://authenticator:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
            PGRST_DB_SCHEMAS: "public,storage,graphql_public"
            PGRST_DB_ANON_ROLE: anon
            PGRST_JWT_SECRET: ${JWT_SECRET}
            PGRST_DB_USE_LEGACY_GUCS: "false"
            PGRST_APP_SETTINGS_JWT_SECRET: ${JWT_SECRET}
            PGRST_APP_SETTINGS_JWT_EXP: 3600
        command: "postgrest"

    realtime:
        # This container name looks inconsistent but is correct because realtime constructs tenant id by parsing the subdomain
        container_name: realtime-dev.supabase-realtime
        image: supabase/realtime:v2.28.32
        depends_on:
            db:
                # Disable this if you are using an external Postgres database
                condition: service_healthy
            analytics:
                condition: service_healthy
        healthcheck:
            test:
                [
                    "CMD",
                    "curl",
                    "-sSfL",
                    "--head",
                    "-o",
                    "/dev/null",
                    "-H",
                    "Authorization: Bearer ${ANON_KEY}",
                    "http://localhost:4000/api/tenants/realtime-dev/health",
                ]
            timeout: 5s
            interval: 5s
            retries: 3
        restart: unless-stopped
        environment:
            PORT: 4000
            DB_HOST: ${POSTGRES_HOST}
            DB_PORT: ${POSTGRES_PORT}
            DB_USER: supabase_admin
            DB_PASSWORD: ${POSTGRES_PASSWORD}
            DB_NAME: ${POSTGRES_DB}
            DB_AFTER_CONNECT_QUERY: "SET search_path TO _realtime"
            DB_ENC_KEY: supabaserealtime
            API_JWT_SECRET: ${JWT_SECRET}
            FLY_ALLOC_ID: fly123
            FLY_APP_NAME: realtime
            SECRET_KEY_BASE: UpNVntn3cDxHJpq99YMc1T1AQgQpc8kfYTuRgBiYa15BLrx8etQoXz3gZv1/u2oq
            ERL_AFLAGS: -proto_dist inet_tcp
            ENABLE_TAILSCALE: "false"
            DNS_NODES: "''"
        command: >
            sh -c "/app/bin/migrate && /app/bin/realtime eval 'Realtime.Release.seeds(Realtime.Repo)' && /app/bin/server"

    # To use S3 backed storage: docker compose -f docker-compose.yml -f docker-compose.s3.yml up
    storage:
        container_name: supabase-storage
        image: supabase/storage-api:v1.0.6
        depends_on:
            db:
                # Disable this if you are using an external Postgres database
                condition: service_healthy
            rest:
                condition: service_started
            imgproxy:
                condition: service_started
        healthcheck:
            test:
                [
                    "CMD",
                    "wget",
                    "--no-verbose",
                    "--tries=1",
                    "--spider",
                    "http://127.0.0.1:5000/status",
                ]
            timeout: 5s
            interval: 5s
            retries: 3
        restart: unless-stopped
        environment:
            ANON_KEY: ${ANON_KEY}
            SERVICE_KEY: ${SERVICE_ROLE_KEY}
            POSTGREST_URL: http://rest:3000
            PGRST_JWT_SECRET: ${JWT_SECRET}
            DATABASE_URL: postgres://supabase_storage_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
            FILE_SIZE_LIMIT: 52428800
            STORAGE_BACKEND: file
            FILE_STORAGE_BACKEND_PATH: /var/lib/storage
            TENANT_ID: stub
            # TODO: https://github.com/supabase/storage-api/issues/55
            REGION: stub
            GLOBAL_S3_BUCKET: stub
            ENABLE_IMAGE_TRANSFORMATION: "true"
            IMGPROXY_URL: http://imgproxy:5001
        volumes:
            - ./volumes/storage:/var/lib/storage:z

    imgproxy:
        container_name: supabase-imgproxy
        image: darthsim/imgproxy:v3.8.0
        healthcheck:
            test: ["CMD", "imgproxy", "health"]
            timeout: 5s
            interval: 5s
            retries: 3
        environment:
            IMGPROXY_BIND: ":5001"
            IMGPROXY_LOCAL_FILESYSTEM_ROOT: /
            IMGPROXY_USE_ETAG: "true"
            IMGPROXY_ENABLE_WEBP_DETECTION: "true"
        volumes:
            - ./volumes/storage:/var/lib/storage:z

    meta:
        container_name: supabase-meta
        image: supabase/postgres-meta:v0.80.0
        depends_on:
            db:
                # Disable this if you are using an external Postgres database
                condition: service_healthy
            analytics:
                condition: service_healthy
        restart: unless-stopped
        environment:
            PG_META_PORT: 8080
            PG_META_DB_HOST: ${POSTGRES_HOST}
            PG_META_DB_PORT: ${POSTGRES_PORT}
            PG_META_DB_NAME: ${POSTGRES_DB}
            PG_META_DB_USER: supabase_admin
            PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}

    functions:
        container_name: supabase-edge-functions
        image: supabase/edge-runtime:v1.45.2
        restart: unless-stopped
        depends_on:
            analytics:
                condition: service_healthy
        environment:
            JWT_SECRET: ${JWT_SECRET}
            SUPABASE_URL: http://kong:8000
            SUPABASE_ANON_KEY: ${ANON_KEY}
            SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
            SUPABASE_DB_URL: postgresql://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
            # TODO: Allow configuring VERIFY_JWT per function. This PR might help: https://github.com/supabase/cli/pull/786
            VERIFY_JWT: "false"
        volumes:
            - ./volumes/functions:/home/deno/functions:Z
        command:
            - start
            - --main-service
            - /home/deno/functions/main

    analytics:
        container_name: supabase-analytics
        image: supabase/logflare:1.4.0
        healthcheck:
            test: ["CMD", "curl", "http://localhost:4000/health"]
            timeout: 5s
            interval: 5s
            retries: 10
        restart: unless-stopped
        depends_on:
            db:
                # Disable this if you are using an external Postgres database
                condition: service_healthy
        # Uncomment to use Big Query backend for analytics
        # volumes:
        #   - type: bind
        #     source: ${PWD}/gcloud.json
        #     target: /opt/app/rel/logflare/bin/gcloud.json
        #     read_only: true
        environment:
            LOGFLARE_NODE_HOST: 127.0.0.1
            DB_USERNAME: supabase_admin
            DB_DATABASE: ${POSTGRES_DB}
            DB_HOSTNAME: ${POSTGRES_HOST}
            DB_PORT: ${POSTGRES_PORT}
            DB_PASSWORD: ${POSTGRES_PASSWORD}
            DB_SCHEMA: _analytics
            LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
            LOGFLARE_SINGLE_TENANT: true
            LOGFLARE_SUPABASE_MODE: true
            LOGFLARE_MIN_CLUSTER_SIZE: 1

            # Comment variables to use Big Query backend for analytics
            POSTGRES_BACKEND_URL: postgresql://supabase_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
            POSTGRES_BACKEND_SCHEMA: _analytics
            LOGFLARE_FEATURE_FLAG_OVERRIDE: multibackend=true
            # Uncomment to use Big Query backend for analytics
            # GOOGLE_PROJECT_ID: ${GOOGLE_PROJECT_ID}
            # GOOGLE_PROJECT_NUMBER: ${GOOGLE_PROJECT_NUMBER}
        ports:
            - 4000:4000

    # Comment out everything below this point if you are using an external Postgres database
    db:
        container_name: supabase-db
        image: supabase/postgres:15.1.1.41
        healthcheck:
            test: pg_isready -U postgres -h localhost
            interval: 5s
            timeout: 5s
            retries: 10
        depends_on:
            vector:
                condition: service_healthy
        command:
            - postgres
            - -c
            - config_file=/etc/postgresql/postgresql.conf
            - -c
            - log_min_messages=fatal # prevents Realtime polling queries from appearing in logs
        restart: unless-stopped
        ports:
            # Pass down internal port because it's set dynamically by other services
            - ${POSTGRES_PORT}:${POSTGRES_PORT}
        environment:
            POSTGRES_HOST: /var/run/postgresql
            PGPORT: ${POSTGRES_PORT}
            POSTGRES_PORT: ${POSTGRES_PORT}
            PGPASSWORD: ${POSTGRES_PASSWORD}
            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
            PGDATABASE: ${POSTGRES_DB}
            POSTGRES_DB: ${POSTGRES_DB}
            JWT_SECRET: ${JWT_SECRET}
            JWT_EXP: 3600
        volumes:
            - ./volumes/db/realtime.sql:/docker-entrypoint-initdb.d/migrations/99-realtime.sql:Z
            # Must be superuser to create event trigger
            - ./volumes/db/webhooks.sql:/docker-entrypoint-initdb.d/init-scripts/98-webhooks.sql:Z
            # Must be superuser to alter reserved role
            - ./volumes/db/roles.sql:/docker-entrypoint-initdb.d/init-scripts/99-roles.sql:Z
            # Initialize the database settings with JWT_SECRET and JWT_EXP
            - ./volumes/db/jwt.sql:/docker-entrypoint-initdb.d/init-scripts/99-jwt.sql:Z
            # PGDATA directory is persisted between restarts
            - ./volumes/db/data:/var/lib/postgresql/data:Z
            # Changes required for Analytics support
            - ./volumes/db/logs.sql:/docker-entrypoint-initdb.d/migrations/99-logs.sql:Z
            # Use named volume to persist pgsodium decryption key between restarts
            - db-config:/etc/postgresql-custom

    vector:
        container_name: supabase-vector
        image: timberio/vector:0.28.1-alpine
        healthcheck:
            test:
                [
                    "CMD",
                    "wget",
                    "--no-verbose",
                    "--tries=1",
                    "--spider",
                    "http://vector:9001/health",
                ]
            timeout: 5s
            interval: 5s
            retries: 3
        volumes:
            - ./volumes/logs/vector.yml:/etc/vector/vector.yml:ro
            - ${DOCKER_SOCKET_LOCATION}:/var/run/docker.sock:ro
        environment:
            LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
        command: ["--config", "etc/vector/vector.yml"]

volumes:
    db-config:
